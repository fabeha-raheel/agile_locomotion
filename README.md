# MS Thesis: Agile Locomotion & Navigation of Quadrupedal Robots using Learning-based Approaches

**Author:** Fabeha Raheel  
**Supervisor:** Dr. Umar Shahbaz Khan  
**Guidance & Evaluation Committee:** Dr. Hamid Jabbar, Dr. Tahir Habib Nawaz, Dr. Umer Izhar  
**Institution:** National University of Sciences & Technology (NUST)  

---

## ğŸ“˜ Abstract

Quadrupedal robots have become a popular research avenue in recent years due to their potential to revolutionize various fields, including exploration, search-and-rescue operations and assistance in urban environments. The aim of quadrupedal research is to leverage bio-inspired locomotion capabilities in robots for agile locomotion and navigation in complex, unstructured terrains. However, achieving agile navigation with quadrupedal robots is exceptionally challenging due to the highly non-linear and complex nature of the problem. 

This research aims to develop a **fully-learned, model-free agile locomotion and navigation framework** for low-cost quadrupedal robots such as the Unitree Go1. The proposed approach uses **Deep Reinforcement Learning** to train the robot to execute advanced locomotion maneuvers such as walking, jumping, climbing, and leaping, based on limited perception of the environment and noisy state information.  
The framework is developed and trained in simulation using **NVIDIA Isaac Gym**, leveraging techniques such as **Domain Randomization** and **Curriculum Learning** to minimize the reality gap and ensure robust performance. The overarching goal is to demonstrate that **highly agile locomotion behaviors**, traditionally dependent on sophisticated control pipelines and expensive sensory systems, can instead be achieved through **end-to-end model-free learning** using affordable hardware and minimal sensory input.

---

## ğŸš€ Research Objective

To develop a **monolithic, end-to-end state-to-action policy** that enables low-cost quadrupedal robots with limited perception capabilities and noisy state information to learn and execute a diverse range of agile locomotion skills, such as:
- Walking
- Climbing
- Jumping
- Leaping

This policy enables **zero-shot generalization** to unseen robot platforms and terrains â€” demonstrating successful transfer from **Unitree A1 (training)** to **Unitree Go1 (testing)**.

---

## ğŸ§  Methodology Overview

### ğŸ”¹ Learning Approach
- **Deep Reinforcement Learning (DRL)** using the [RSL RL](https://github.com/leggedrobotics/rsl_rl) framework  
- **Teacherâ€“Student Learning (Privileged Learning):**  
  - *Teacher Policy:* trained with privileged terrain and state information  
  - *Student Policy:* trained via **Behavior Cloning** and **DAGGER** (Dataset Aggregation) using only depth perception
- **Domain Randomization** and **Curriculum Learning** for robustness and transferability  

### ğŸ”¹ Policy Architecture
- **Depth Encoder:** encodes raw terrain depth images  
- **GRU Network:** captures temporal dependencies  
- **Actor Network:** outputs motor actions (no critic used during deployment)  
- **State Estimator Network:** predicts unobservable privileged states such as linear velocity, friction, and motor strength  

### ğŸ”¹ Simulation Environment
- **Simulator:** NVIDIA Isaac Gym (Preview 3 / 4)
- **Programming Language:** Python  
- **Frameworks:** PyTorch, RSL RL, ROS 2  

### ğŸ”¹ Privileged Information (Teacher Policy)
- Terrain scandots  
- Base linear velocity  
- Physical parameters (mass, friction coefficients, motor strengths)

---

## ğŸŒ Terrain & Navigation Setup

- **Navigation:** waypoint-based with adaptive heading adjustment based on obstacle geometry  
- **Terrain Representation:** depth images (for student), scandots (for teacher)  
- **Procedurally Generated Obstacles:**
  | Parameter | Range |
  |------------|--------|
  | Obstacle Height | [-0.45, 1.2] m |
  | Gap Size | [0.02, 0.08] m |
  | Stepping Stone Distance | [0.02, 0.08] m |
  | Max Slope Inclination | 1.5 rad |

---

## ğŸ§© Repository Structure
```
Directory structure:
â””â”€â”€ fabeha-raheel-agile_locomotion/
    â”œâ”€â”€ README.md
    â”œâ”€â”€ install.sh
    â”œâ”€â”€ LICENSE
    â”œâ”€â”€ legged_gym/
    â”‚   â”œâ”€â”€ LICENSE
    â”‚   â”œâ”€â”€ requirements.txt
    â”‚   â”œâ”€â”€ setup.py
    â”‚   â”œâ”€â”€ legged_gym/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ envs/
    â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”‚   â”œâ”€â”€ a1/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ a1_config.py
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ a1_parkour_config.py
    â”‚   â”‚   â”‚   â”œâ”€â”€ base/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ base_config.py
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ base_task.py
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ legged_robot_config.py
    â”‚   â”‚   â”‚   â””â”€â”€ go1/
    â”‚   â”‚   â”‚       â””â”€â”€ go1_config.py
    â”‚   â”‚   â”œâ”€â”€ scripts/
    â”‚   â”‚   â”‚   â”œâ”€â”€ evaluate.py
    â”‚   â”‚   â”‚   â”œâ”€â”€ fetch.py
    â”‚   â”‚   â”‚   â”œâ”€â”€ play.py
    â”‚   â”‚   â”‚   â”œâ”€â”€ save_jit.py
    â”‚   â”‚   â”‚   â”œâ”€â”€ train.py
    â”‚   â”‚   â”‚   â”œâ”€â”€ visualize.py
    â”‚   â”‚   â”‚   â””â”€â”€ legged_gym/
    â”‚   â”‚   â”‚       â””â”€â”€ envs/
    â”‚   â”‚   â”‚           â”œâ”€â”€ a1/
    â”‚   â”‚   â”‚           â”‚   â””â”€â”€ a1_config.py
    â”‚   â”‚   â”‚           â””â”€â”€ base/
    â”‚   â”‚   â”‚               â””â”€â”€ legged_robot_config.py
    â”‚   â”‚   â”œâ”€â”€ tests/
    â”‚   â”‚   â”‚   â””â”€â”€ test_env.py
    â”‚   â”‚   â””â”€â”€ utils/
    â”‚   â”‚       â””â”€â”€ ...
    â”‚   â”œâ”€â”€ licenses/
    â”‚   â””â”€â”€ resources/
    â”‚       â”œâ”€â”€ actuator_nets/
    â”‚       â”‚   â””â”€â”€ anydrive_v3_lstm.pt
    â”‚       â””â”€â”€ robots/
    â”‚           â”œâ”€â”€ a1/
    â”‚           â”œâ”€â”€ anymal_b/
    â”‚           â”œâ”€â”€ anymal_c/
    â”‚           â””â”€â”€ cassie/
    â””â”€â”€ rsl_rl/
        â””â”€â”€ ...
```


---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Create Conda Environment
```bash
conda create -n quad_env python=3.8
conda activate quad_env
```
### 2ï¸âƒ£ Install Dependencies
```bash
pip3 install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio==0.10.0+cu113 \
    -f https://download.pytorch.org/whl/cu113/torch_stable.html
```
### 3ï¸âƒ£ Clone Repository
```bash
git clone https://github.com/fabeha-raheel/agile_locomotion.git
cd agile_locomotion
```
### 4ï¸âƒ£ Install Isaac Gym

Download Isaac Gym binaries from NVIDIA Developer
.
Originally trained with Preview 3, compatible with Preview 4.
```bash
cd isaacgym/python && pip install -e .
```
### 5ï¸âƒ£ Install Local Packages
```bash
cd ~/agile_locomotion/rsl_rl && pip install -e .
cd ~/agile_locomotion/legged_gym && pip install -e .
```
### 6ï¸âƒ£ Install Additional Python Dependencies
```bash
pip install "numpy<1.24" pydelatin wandb tqdm opencv-python ipdb pyfqmr flask
```

## ğŸ§ª Running the Code
### â–¶ï¸ Play Base (Teacher) Policy
```bash
python play.py --exptid xxx-xx
```

### â–¶ï¸ Play Distilled (Student) Policy
```bash
python play.py --exptid yyy-yy --delay --use_camera
```

## ğŸ“Š Results & Evaluation

The learned skills were tested by deploying the **student policy** obtained after knowledge distillation.  

| **Evaluation Parameter** | **Details** |
|---------------------------|-------------|
| **Environment** | 5Ã—5 patch testbed |
| **Difficulty Levels** | 1 (Easy) â†’ 5 (Hard) |
| **Trials per Course** | 20 |
| **Metrics** | Success rate, traversal completion, stability |

---

### ğŸ¥ Demonstration Videos

- [Unitree Go1 Testing â€“ Part 1](https://youtu.be/muhaUtQNDQw)  
- [Unitree Go1 Testing â€“ Part 2](https://youtu.be/O6sVChRo0nw)  
- [Unitree A1 Testing](https://youtu.be/IDnxZjtDjd0)

---

## ğŸ“š Key Techniques Summary

| **Technique** | **Purpose** |
|----------------|-------------|
| **Deep RL (PPO)** | Train locomotion policy end-to-end |
| **Teacherâ€“Student Learning** | Distill privileged policy to deployable one |
| **DAGGER** | Iterative knowledge transfer |
| **Domain Randomization** | Improve sim-to-real transfer |
| **Curriculum Learning** | Gradual difficulty scaling |

---

## ğŸ§¾ Citation

If you find this work useful, please cite:

```bibtex
@thesis{raheel2025agilelocomotion,
  author       = {Fabeha Raheel},
  title        = {Agile Locomotion & Navigation of Quadrupedal Robots using Learning-based Approaches},
  school       = {National University of Sciences & Technology (NUST)},
  year         = {2025},
  supervisor   = {Dr. Umar Shahbaz Khan}
}
```

## ğŸŒŸ Acknowledgments

This research was carried out under the supervision of **Dr. Umar Shahbaz Khan** at the **National University of Sciences & Technology (NUST)**.  
Special thanks to **Dr. Hamid Jabbar**, **Dr. Tahir Habib Nawaz** and **Dr. Umer Izhar** for their valuable feedback during evaluations.

---

## ğŸ§© Keywords

`Quadrupedal Locomotion` Â· `Deep Reinforcement Learning` Â· `Agile Robotics` Â· `Privileged Learning` Â· `Teacher-Student Policy` Â· `Isaac Gym` Â· `Domain Randomization` Â· `Curriculum Learning` Â· `Knowledge Distillation` Â· `Imitation Learning` Â· `Unitree Go1` Â· `Unitree A1`

